{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# 添加源代码路径\n",
    "sys.path.append(\"src\")\n",
    "\n",
    "# 导入自定义模块\n",
    "import gnns.data\n",
    "import gnns.classifier\n",
    "import gnns.metrics\n",
    "from gnns.featurer import DataProcessor\n",
    "\n",
    "# 数据路径设置\n",
    "file_path = \"data\"  # dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# 导入模块中的函数及类\n",
    "from GNN.sample import (\n",
    "    GeneGAT,\n",
    "    create_full_connected_edge_index,\n",
    "    create_correlation_edge_index,\n",
    "    create_knn_edge_index,\n",
    "    train_graph_classifier,\n",
    "    extract_pooling_features,\n",
    "    predict_with_loader,\n",
    "    save_predictions\n",
    ")\n",
    "import gnns.data\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "# 添加中文字体支持\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "\n",
    "# 设置计算设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# 加载和预处理数据\n",
    "def prepare_data():\n",
    "    X, y, gene_names, sample_ids = gnns.data.load_data('data', method='lxs', read=True, use_deg=True)\n",
    "    X, y, train_mask, val_mask, test_mask = gnns.data.get_split_data(X, y, oversample=False)\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_tensor = torch.from_numpy(X).float()\n",
    "    y_tensor = torch.from_numpy(y).long()\n",
    "    train_mask = torch.from_numpy(train_mask)\n",
    "    val_mask = torch.from_numpy(val_mask)\n",
    "    test_mask = torch.from_numpy(test_mask)\n",
    "\n",
    "    X_train = X_tensor[train_mask]\n",
    "    y_train = y_tensor[train_mask]\n",
    "    X_val = X_tensor[val_mask]\n",
    "    y_val = y_tensor[val_mask]\n",
    "    X_test = X_tensor[test_mask]\n",
    "    y_test = y_tensor[test_mask]\n",
    "\n",
    "    print(\"数据集划分：\")\n",
    "    print(f\"  训练样本数: {len(X_train)}\")\n",
    "    print(f\"  验证样本数: {len(X_val)}\")\n",
    "    print(f\"  测试样本数: {len(X_test)}\")\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, sample_ids, test_mask\n",
    "\n",
    "# 创建图结构\n",
    "def create_graph(X_train, method='knn'):\n",
    "    print(f\"\\n使用图构建方法: {method}\")\n",
    "    if method == 'full_connected':\n",
    "        edge_index = create_full_connected_edge_index(X_train.shape[1]).to(device)\n",
    "    elif method == 'correlation':\n",
    "        edge_index = create_correlation_edge_index(X_train.cpu().numpy(), threshold=0.6).to(device)\n",
    "    else:\n",
    "        edge_index = create_knn_edge_index(X_train.cpu().numpy(), k=15, metric='correlation').to(device)\n",
    "\n",
    "    print(f\"创建的图结构: 边数={edge_index.shape[1]}\")\n",
    "    num_features = X_train.shape[1]\n",
    "    if edge_index.numel() > 0:\n",
    "        max_index = edge_index.max().item()\n",
    "        if num_features <= max_index:\n",
    "            print(f\"警告: 特征数量 ({num_features}) <= 边索引中的最大值 ({max_index}). 调整索引...\")\n",
    "            mask = (edge_index[0] < num_features) & (edge_index[1] < num_features)\n",
    "            edge_index = edge_index[:, mask]\n",
    "            print(f\"调整后的图结构: 边数={edge_index.shape[1]}\")\n",
    "    return edge_index\n",
    "\n",
    "# 创建数据加载器\n",
    "def create_data_objects(X, y, edge_index, batch_size=256):\n",
    "    data_list = []\n",
    "    for i in range(len(X)):\n",
    "        x = X[i:i+1].T.float().to(device)\n",
    "        data = Data(x=x, edge_index=edge_index, y=y[i:i+1].to(device))\n",
    "        if data.edge_index.numel() > 0 and data.x.size(0) <= data.edge_index.max().item():\n",
    "            print(f\"警告: 样本 {i} 的节点数不足, 跳过.\")\n",
    "            continue\n",
    "        data_list.append(data)\n",
    "    loader = DataLoader(data_list, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    return loader\n",
    "\n",
    "\n",
    "# 主函数\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='GeneGAT 训练与推理脚本')\n",
    "    parser.add_argument('--load_model', type=str, default='models/k_fold/model_fold_0.pt', help='指定已保存模型的路径, 若提供则直接加载并跳过训练')\n",
    "    # parser.add_argument('--load_model', type=str, default='', help='指定已保存模型的路径, 若提供则直接加载并跳过训练')\n",
    "    parser.add_argument('--image_dir', type=str, default='images/single_run', help='保存图片的目录')\n",
    "    args, unknown = parser.parse_known_args()\n",
    "\n",
    "    os.makedirs(args.image_dir, exist_ok=True)\n",
    "\n",
    "    # 数据准备\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, sample_ids, test_mask = prepare_data()\n",
    "    # 图构建\n",
    "    edge_index = create_graph(X_train, method='full_connected')\n",
    "    # 加载器创建\n",
    "    train_loader = create_data_objects(X_train, y_train, edge_index, batch_size=32)\n",
    "    val_loader   = create_data_objects(X_val,   y_val,   edge_index, batch_size=32)\n",
    "    test_loader  = create_data_objects(X_test,  y_test,  edge_index, batch_size=32)\n",
    "\n",
    "    # 模型实例化\n",
    "    model = GeneGAT(\n",
    "        input_dim=1, output_dim=2, hidden_dim=128, pooling_dim=8,\n",
    "        num_heads=8, gat_layers=2, dropout=0.5,\n",
    "        activation='swish', cluster_num=8, \n",
    "    ).to(device)\n",
    "\n",
    "    # 加载或训练\n",
    "    if args.load_model and os.path.exists(args.load_model):\n",
    "        checkpoint = torch.load(args.load_model, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_threshold = checkpoint.get('threshold', 0.5)\n",
    "        print(f\"已加载模型: {args.load_model}, 阈值: {best_threshold}\")\n",
    "    else:\n",
    "        print(\"\\n开始训练模型...\")\n",
    "        model, best_threshold = train_graph_classifier(\n",
    "            model=model, class_weights=[1,3],\n",
    "            train_data=train_loader, val_data=val_loader,\n",
    "            epochs=300, lr=1e-4, weight_decay=1e-4, patience=100\n",
    "        )\n",
    "\n",
    "    # 推理与评估\n",
    "    y_pred, y_probs, features, metrics = predict_with_loader(model, test_loader, device, threshold=best_threshold)\n",
    "    print(f\"评估结果 -> Accuracy: {metrics['accuracy']:.4f}, F1: {metrics['f1_score']:.4f}, AUC: {metrics['auc']:.4f}\")\n",
    "\n",
    "    # 混淆矩阵与 ROC 曲线\n",
    "    # 绘制混淆矩阵\n",
    "    cm = confusion_matrix(y_test.cpu().numpy(), y_pred.cpu().numpy())\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                annot_kws={'size': 12})\n",
    "    plt.xlabel('预测标签')\n",
    "    plt.ylabel('真实标签')\n",
    "    plt.title('混淆矩阵')\n",
    "    plt.savefig(os.path.join(args.image_dir, 'confusion_matrix.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # 绘制ROC曲线\n",
    "    fpr, tpr, _ = roc_curve(y_test.cpu().numpy(), y_probs[:,1].cpu().numpy())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(fpr, tpr, color='#1e88e5', lw=2, \n",
    "             label=f'ROC曲线 (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0,1], [0,1], '--', color='#757575', lw=1.5)\n",
    "    \n",
    "    plt.xlabel('假阳性率')\n",
    "    plt.ylabel('真阳性率')\n",
    "    plt.title('ROC曲线')\n",
    "    \n",
    "    plt.legend(loc='lower right')\n",
    "    \n",
    "    plt.grid(True, linestyle='--', alpha=0.2)\n",
    "    plt.savefig(os.path.join(args.image_dir, 'roc_curve.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # 生成测试集样本ID列表，确保与预测数量一致\n",
    "    test_sample_ids = None\n",
    "    if sample_ids is not None:\n",
    "        sample_ids_array = np.array(sample_ids)\n",
    "        test_mask_np = test_mask.numpy() if isinstance(test_mask, torch.Tensor) else np.array(test_mask)\n",
    "        if len(test_mask_np) == len(sample_ids_array):\n",
    "            test_sample_ids = sample_ids_array[test_mask_np].tolist()\n",
    "    # 确保结果目录存在\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    pred_df = save_predictions(\n",
    "        y_true=y_test.cpu(),\n",
    "        y_pred=y_pred.cpu(),\n",
    "        y_probs=y_probs.cpu(),\n",
    "        sample_ids=test_sample_ids,\n",
    "        features=features.cpu(),\n",
    "        save_path=os.path.join('results', 'predictions.csv')\n",
    "    )\n",
    "    print(\"推理结果保存在 results/predictions.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基因为节点 提取特征 简单版\n",
    "\n",
    "print(\"\\n提取池化后降维后的特征...\")\n",
    "all_features = {}\n",
    "all_features['test'], pool_labels = extract_pooling_features(\n",
    "    model=model,\n",
    "    data_loader=test_loader,\n",
    "    device=device  \n",
    ")\n",
    "all_features['train'], pool_labels = extract_pooling_features(\n",
    "    model=model,\n",
    "    data_loader=train_loader,\n",
    "    device=device\n",
    ")\n",
    "all_features['val'], pool_labels = extract_pooling_features(\n",
    "    model=model,\n",
    "    data_loader=val_loader,\n",
    "    device=device \n",
    ")\n",
    "all_labels = {}\n",
    "all_labels['test'] = y_test\n",
    "all_labels['train'] = y_train\n",
    "all_labels['val'] = y_val\n",
    "print(\"训练集特征形状:\", all_features['train'].shape)\n",
    "print(\"训练集标签形状:\", all_labels['train'].shape)\n",
    "print(\"验证集特征形状:\", all_features['val'].shape) \n",
    "print(\"验证集标签形状:\", all_labels['val'].shape)\n",
    "print(\"测试集特征形状:\", all_features['test'].shape)\n",
    "print(\"测试集标签形状:\", all_labels['test'].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def xgboost_train_or_search(\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "    user_params=None, param_dist=None,\n",
    "    n_iter=20, random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    简洁版：\n",
    "    - 只用 user_params 时：直接训练并评估\n",
    "    - 否则：在 param_dist 上随机搜索，并包含 user_params\n",
    "    全程静默，使用验证集早停，只打印最终结果\n",
    "    \"\"\"\n",
    "    # 基础配置\n",
    "    base = {\n",
    "        'objective': 'binary:logistic' if len(np.unique(y_train)) == 2 else 'multi:softprob',\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'logloss',\n",
    "        'verbosity': 0,\n",
    "        'random_state': random_state\n",
    "    }\n",
    "\n",
    "    # 仅直接训练自定义参数\n",
    "    if user_params and not param_dist:\n",
    "        cfg = {**base, **user_params}\n",
    "        model = xgb.XGBClassifier(**cfg)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "        acc = accuracy_score(y_test, model.predict(X_test))\n",
    "        print(\"使用自定义参数：\", cfg)\n",
    "        print(\"测试集准确率：\", acc)\n",
    "        return model, cfg\n",
    "\n",
    "    # 构建参数候选列表\n",
    "    candidates = []\n",
    "    if user_params:\n",
    "        candidates.append(user_params)\n",
    "    if param_dist:\n",
    "        candidates += list(ParameterSampler(param_dist, n_iter=n_iter, random_state=random_state))\n",
    "\n",
    "    best_score, best_cfg, best_model = 0, None, None\n",
    "    # 随机搜索\n",
    "    for params in candidates:\n",
    "        cfg = {**base, **params}\n",
    "        model = xgb.XGBClassifier(**cfg)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "        score = accuracy_score(y_val, model.predict(X_val))\n",
    "        if score > best_score:\n",
    "            best_score, best_cfg, best_model = score, cfg, model\n",
    "\n",
    "    # 最终评估并打印\n",
    "    test_acc = accuracy_score(y_test, best_model.predict(X_test))\n",
    "    print(\"最优参数：\", best_cfg)\n",
    "    print(\"测试集准确率：\", test_acc)\n",
    "    return best_model, best_cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGboost\n",
    "import numpy as np\n",
    "\n",
    "# 定义超参数搜索空间\n",
    "param_dist = {\n",
    "}\n",
    "\n",
    "user_params =   {'objective': 'binary:logistic', 'use_label_encoder': False, 'eval_metric': 'logloss', 'verbosity': 0, 'random_state': 42, 'subsample': 0.8, 'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 0.8}\n",
    "# 打印参数列表，便于确认搜索空间\n",
    "print(\"超参数列表 (param_dist):\")\n",
    "for k, v in param_dist.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# XGBoost: 支持 raw/graph/hybrid 特征调用\n",
    "for feature_type in ['raw', 'graph', 'hybrid']:\n",
    "    if feature_type == 'raw':\n",
    "        X_tr, y_tr = X_train, y_train\n",
    "        X_va, y_va = X_test,  y_test\n",
    "    elif feature_type == 'graph':\n",
    "        X_tr, y_tr = all_features['train'], all_labels['train']\n",
    "        X_va, y_va = all_features['test'],  all_labels['test']\n",
    "    else:  # hybrid\n",
    "        X_tr = np.hstack([X_train, all_features['train']])\n",
    "        y_tr = y_train\n",
    "        X_va = np.hstack([X_test,  all_features['test']])\n",
    "        y_va = y_test\n",
    "\n",
    "    print(f\"Using {feature_type} features...\")\n",
    "    best_model, best_params = xgboost_train_or_search(\n",
    "        X_tr, y_tr,\n",
    "        X_va, y_va,\n",
    "        X_va, y_va,\n",
    "        user_params=user_params,\n",
    "        param_dist=None,\n",
    "        n_iter=30,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "\n",
    "def random_forest_train_or_search(\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "    user_params=None, param_dist=None,\n",
    "    n_iter=20, random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    随机森林训练/搜索简洁版：\n",
    "    - 只给 user_params 时：直接训练并评估\n",
    "    - 否则：在 param_dist 上随机采样，包括 user_params\n",
    "    全程静默，只在末尾打印最优参数及准确率/F1。\n",
    "    返回 (best_model, best_params)\n",
    "    \"\"\"\n",
    "    # Tensor 转 NumPy\n",
    "    def to_np(x):\n",
    "        return x.detach().cpu().numpy() if isinstance(x, torch.Tensor) else x\n",
    "\n",
    "    X_train, y_train = to_np(X_train), to_np(y_train)\n",
    "    X_val,   y_val   = to_np(X_val),   to_np(y_val)\n",
    "    X_test,  y_test  = to_np(X_test),  to_np(y_test)\n",
    "\n",
    "    # 构建候选参数列表\n",
    "    candidates = []\n",
    "    if user_params:\n",
    "        candidates.append(user_params)\n",
    "    if param_dist:\n",
    "        candidates += list(ParameterSampler(param_dist, n_iter=n_iter, random_state=random_state))\n",
    "\n",
    "    # 如果仅提供自定义参数，忽略候选搜索\n",
    "    if user_params and not param_dist:\n",
    "        candidates = [user_params]\n",
    "\n",
    "    best_score = 0.0\n",
    "    best_cfg = None\n",
    "    best_model = None\n",
    "\n",
    "    # 遍历候选\n",
    "    for cfg in candidates:\n",
    "        model = RandomForestClassifier(random_state=random_state, n_jobs=-1, **cfg)\n",
    "        model.fit(X_train, y_train)\n",
    "        val_pred = model.predict(X_val)\n",
    "        score = accuracy_score(y_val, val_pred)\n",
    "        if score > best_score:\n",
    "            best_score, best_cfg, best_model = score, cfg, model\n",
    "\n",
    "    # 最终评估\n",
    "    test_pred = best_model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, test_pred)\n",
    "\n",
    "    print(\"最优随机森林参数：\", best_cfg)\n",
    "    print(f\"测试集集准确率: {best_score:.4f}\")\n",
    "\n",
    "    return best_model, best_cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF\n",
    "import numpy as np\n",
    "# 1. 定义 RF 参数搜索空间\n",
    "param_dist = {\n",
    "}\n",
    "user_params = {'n_estimators': 25, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': None, 'max_depth': 20}\n",
    "print(\"随机森林参数调优范围：\")\n",
    "for k, v in param_dist.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# 2. 针对 raw / graph / hybrid 三种特征类型调用\n",
    "for feature_type in ['raw', 'graph', 'hybrid']:\n",
    "    if feature_type == 'raw':\n",
    "        X_tr, y_tr = X_train, y_train\n",
    "        X_va, y_va = X_val,   y_val\n",
    "        X_te, y_te = X_test,  y_test\n",
    "\n",
    "    elif feature_type == 'graph':\n",
    "        X_tr, y_tr = all_features['train'], all_labels['train']\n",
    "        X_va, y_va = all_features['val'],   all_labels['val']\n",
    "        X_te, y_te = all_features['test'],  all_labels['test']\n",
    "\n",
    "    else:  # hybrid\n",
    "        X_tr = np.hstack([X_train,       all_features['train']])\n",
    "        y_tr = y_train\n",
    "        X_va = np.hstack([X_val,         all_features['val']])\n",
    "        y_va = y_val\n",
    "        X_te = np.hstack([X_test,        all_features['test']])\n",
    "        y_te = y_test\n",
    "\n",
    "    print(f\"\\nUsing {feature_type} features for RF...\")\n",
    "    best_model, best_params = random_forest_train_or_search(\n",
    "        X_tr, y_tr,\n",
    "        X_va, y_va,\n",
    "        X_te, y_te,\n",
    "        user_params=user_params,\n",
    "        param_dist=None,\n",
    "        n_iter=30,\n",
    "        random_state=42\n",
    "    )\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def svm_train_or_search(\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    X_test, y_test,\n",
    "    user_params=None, param_dist=None,\n",
    "    n_iter=20, random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    SVM 训练/搜索简洁版：\n",
    "    - 只给 user_params 时：直接训练并评估\n",
    "    - 否则：在 param_dist 上随机采样，包括 user_params\n",
    "    全程静默，只在末尾打印最优参数及准确率。\n",
    "    返回 (best_model, best_params)\n",
    "    \"\"\"\n",
    "    def to_np(x):\n",
    "        return x.detach().cpu().numpy() if isinstance(x, torch.Tensor) else x\n",
    "\n",
    "    X_train, y_train = to_np(X_train), to_np(y_train)\n",
    "    X_val,   y_val   = to_np(X_val),   to_np(y_val)\n",
    "    X_test,  y_test  = to_np(X_test),  to_np(y_test)\n",
    "\n",
    "    # 构建候选参数列表\n",
    "    candidates = []\n",
    "    if user_params:\n",
    "        candidates.append(user_params)\n",
    "    if param_dist:\n",
    "        candidates += list(ParameterSampler(param_dist, n_iter=n_iter, random_state=random_state))\n",
    "    if user_params and not param_dist:\n",
    "        candidates = [user_params]\n",
    "\n",
    "    best_score = 0.0\n",
    "    best_cfg = None\n",
    "    best_model = None\n",
    "\n",
    "    for cfg in candidates:\n",
    "        model = SVC(random_state=random_state, **cfg)\n",
    "        model.fit(X_train, y_train)\n",
    "        val_pred = model.predict(X_val)\n",
    "        score = accuracy_score(y_val, val_pred)\n",
    "        if score > best_score:\n",
    "            best_score, best_cfg, best_model = score, cfg, model\n",
    "\n",
    "    test_pred = best_model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, test_pred)\n",
    "\n",
    "    print(\"最优 SVM 参数：\", best_cfg)\n",
    "    print(f\"测试集准确率: {test_acc:.4f}\")\n",
    "\n",
    "    return best_model, best_cfg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 定义 SVM 参数搜索空间\n",
    "param_dist = {\n",
    "}\n",
    "user_params =  {'tol': 0.01, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3, 'C': 100}\n",
    "\n",
    "\n",
    "# 2. 针对 raw / graph / hybrid 三种特征类型调用\n",
    "for feature_type in ['raw', 'graph', 'hybrid']:\n",
    "    if feature_type == 'raw':\n",
    "        X_tr, y_tr = X_train, y_train\n",
    "        X_va, y_va = X_val,   y_val\n",
    "        X_te, y_te = X_test,  y_test\n",
    "\n",
    "    elif feature_type == 'graph':\n",
    "        X_tr, y_tr = all_features['train'], all_labels['train']\n",
    "        X_va, y_va = all_features['val'],   all_labels['val']\n",
    "        X_te, y_te = all_features['test'],  all_labels['test']\n",
    "\n",
    "    else:  # hybrid\n",
    "        X_tr = np.hstack([X_train,       all_features['train']])\n",
    "        y_tr = y_train\n",
    "        X_va = np.hstack([X_val,         all_features['val']])\n",
    "        y_va = y_val\n",
    "        X_te = np.hstack([X_test,        all_features['test']])\n",
    "        y_te = y_test\n",
    "\n",
    "    print(f\"\\nUsing {feature_type} features for SVM...\")\n",
    "    best_model, best_params = svm_train_or_search(\n",
    "        X_tr, y_tr,\n",
    "        X_va, y_va,\n",
    "        X_te, y_te,\n",
    "        user_params=user_params,\n",
    "        param_dist=None,\n",
    "        n_iter=30,\n",
    "        random_state=42\n",
    "    )\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
